{"ast":null,"code":"var _jsxFileName = \"C:\\\\Users\\\\hp\\\\Desktop\\\\Sudoku\\\\my-app\\\\src\\\\About.js\";\nimport React, { Component } from \"react\";\nimport './About.css';\nexport default class About extends Component {\n  constructor(props) {\n    super(props);\n    this.state = {};\n    this.chooseAbout = this.chooseAbout.bind(this);\n  }\n\n  chooseAbout(alg) {\n    switch (alg) {\n      case 1:\n        return `Backtracking is essentially structured guessing until you find \n                    a solution that works. In this algorithm, we start at the top\n                    left corner square. We choose the lowest number, 1 through 9, that\n                    doesn't conflict with row, columnn, or 3x3 square of the current square.\n                     Then we move on to the next square and do the same. We keep \n                    doing this until we reach a square where none of the numbers \n                    1-9 work. Then we back up to the previous square. If no numbers\n                    work in that square, then we back up again, and again, and so on\n                    until we find a square where a new value works. Then we move on\n                    to the next square from there and restart the whole process.\n                    `;\n\n      case 2:\n        return `Hill Climbing is an example of a greedy algorithm, meaning that\n                    at each step in the algorithm, it chooses the option that maximizes\n                    its short-term gain to the next step. In this implementation, we\n                    define some amount of Error in the grid. The Error is the sum of\n                    all the duplicates in all of the rows and columns, and is shown on\n                    the right side of the screen. The algorithm starts by filling in the\n                    3x3 squares with all the numbers 1-9, so that there are no\n                    duplicates in the 3x3 squares and only duplicates in the rows and\n                    columns. Then the algorithm chooses two random 1x1 squares in a random\n                    3x3 square. If switching their values lowers the number of duplicates\n                    in the rows and columns of the grid, then the error is lower and\n                    the algorithm will make this switch. If the switch increases the\n                    number of errors in the board, then the algorithm will not make this\n                    switch. It looks at around 50000 moves, but quickly reaches a point\n                    where there aren't any moves that will lower the error, even though\n                    the grid is not solved. This is called a \"local minimum\" in the error,\n                    but it is not the \"absolute minimum\" of 0 error that we want.`;\n\n      case 3:\n        return `Simulated Annealing is based on how molten metals cool into solid\n                    form. It is very similar to Hill Climbing. It starts by filling in\n                    all the 3x3 squares with the digits 1-9. Then we define the Error\n                    as the total number of duplicates in the rows and columns. The 3x3\n                    square have no duplicates so the do not contribute to the error.\n                    The algorithm then chooses two random 1x1 square in a random 3x3 \n                    square. If switching their values decreases the total error in the\n                    board, then the algorithm makes this switch. Otherwise, it has a\n                    chance to make this switch and a chance to not make this switch.\n                    At the beginning, there is about an 80% change that the algorithm\n                    will make this \"bad\" switch. Over time, the chance to make a \"bad\"\n                    switch goes down so that by the end there is almost a 0% chance.\n                    In this way, the algorithm is much like Hill Climbing, but it\n                    allows the board to change a lot more at the beginning, and \"cool\"\n                    into a solution with less errors. This helps the algorithm break\n                    out of local minima in the error that Hill Climbing gets stuck\n                    at. If you run both of these a few times, you'll see that Hill\n                    Climbing usually ends with around 10 errors, but Simulated\n                    Annealing usually ends with 2 or 3, which is much better.`;\n\n      case 4:\n        return `The genetic algorithm replicates natural selection in organisms.\n                    It starts off by creating 1000 different random boards. This is\n                    the first generation. It counts the number of errors in the\n                    rows, columns, and 3x3 squares for each board. It then creates a\n                    second generation by making 1000 \"children\" boards from the first\n                    generation. A child is created by selecting two \"parent\" boards\n                    from the first generation and mixing their values together.\n                    Importantly, boards in the first generation with lower errors are\n                    selected as parents more often so that children with similarly \n                    low errors are produced more than children with higher error. In\n                    this way we are \"selecting\" the more fit boards to reproduce more\n                    in the same way nature selects more fit organisms to reproduce more.\n                    Each child also undergoes a mutation process which gives a small\n                    chance for any of its values that it got from its parents to\n                    randomly change to another value. This reflects Gene mutation in\n                    natural selection. When 1000 children have been created, they\n                    become the parents to make the 3rd generation. And those children\n                    become parents to make the 4th generation, and so on. This\n                    algorithm runs for 1000 generations before stopping.`;\n\n      default:\n        return \"Choose an algorithm!\";\n    }\n  }\n\n  render() {\n    return /*#__PURE__*/React.createElement(\"span\", {\n      className: \"About\",\n      __self: this,\n      __source: {\n        fileName: _jsxFileName,\n        lineNumber: 103,\n        columnNumber: 9\n      }\n    }, this.chooseAbout(this.props.selectedAlg));\n  }\n\n}","map":{"version":3,"sources":["C:/Users/hp/Desktop/Sudoku/my-app/src/About.js"],"names":["React","Component","About","constructor","props","state","chooseAbout","bind","alg","render","selectedAlg"],"mappings":";AAAA,OAAOA,KAAP,IAAgBC,SAAhB,QAAiC,OAAjC;AACA,OAAO,aAAP;AAEA,eAAe,MAAMC,KAAN,SAAoBD,SAApB,CAA6B;AACxCE,EAAAA,WAAW,CAACC,KAAD,EAAQ;AACf,UAAMA,KAAN;AACA,SAAKC,KAAL,GAAa,EAAb;AAEA,SAAKC,WAAL,GAAmB,KAAKA,WAAL,CAAiBC,IAAjB,CAAsB,IAAtB,CAAnB;AACD;;AAEHD,EAAAA,WAAW,CAACE,GAAD,EAAM;AACb,YAAQA,GAAR;AACI,WAAK,CAAL;AACI,eACK;AACrB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,qBAXgB;;AAcJ,WAAK,CAAL;AACI,eACK;AACrB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,kFAjBgB;;AAoBJ,WAAK,CAAL;AACI,eACK;AACrB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,8EAnBgB;;AAsBJ,WAAK,CAAL;AACI,eACK;AACrB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,yEAnBgB;;AAsBJ;AACI,eAAO,sBAAP;AApFR;AAsFH;;AAEDC,EAAAA,MAAM,GAAG;AACL,wBACA;AAAM,MAAA,SAAS,EAAC,OAAhB;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,OAAyB,KAAKH,WAAL,CAAiB,KAAKF,KAAL,CAAWM,WAA5B,CAAzB,CADA;AAGH;;AArGuC","sourcesContent":["import React, { Component } from \"react\";\r\nimport './About.css'\r\n\r\nexport default class About extends Component{\r\n    constructor(props) {\r\n        super(props);\r\n        this.state = {\r\n        };\r\n        this.chooseAbout = this.chooseAbout.bind(this)\r\n      }\r\n\r\n    chooseAbout(alg) {\r\n        switch (alg) {\r\n            case 1:\r\n                return (\r\n                    `Backtracking is essentially structured guessing until you find \r\n                    a solution that works. In this algorithm, we start at the top\r\n                    left corner square. We choose the lowest number, 1 through 9, that\r\n                    doesn't conflict with row, columnn, or 3x3 square of the current square.\r\n                     Then we move on to the next square and do the same. We keep \r\n                    doing this until we reach a square where none of the numbers \r\n                    1-9 work. Then we back up to the previous square. If no numbers\r\n                    work in that square, then we back up again, and again, and so on\r\n                    until we find a square where a new value works. Then we move on\r\n                    to the next square from there and restart the whole process.\r\n                    `\r\n                    )\r\n            \r\n            case 2: \r\n                return (\r\n                    `Hill Climbing is an example of a greedy algorithm, meaning that\r\n                    at each step in the algorithm, it chooses the option that maximizes\r\n                    its short-term gain to the next step. In this implementation, we\r\n                    define some amount of Error in the grid. The Error is the sum of\r\n                    all the duplicates in all of the rows and columns, and is shown on\r\n                    the right side of the screen. The algorithm starts by filling in the\r\n                    3x3 squares with all the numbers 1-9, so that there are no\r\n                    duplicates in the 3x3 squares and only duplicates in the rows and\r\n                    columns. Then the algorithm chooses two random 1x1 squares in a random\r\n                    3x3 square. If switching their values lowers the number of duplicates\r\n                    in the rows and columns of the grid, then the error is lower and\r\n                    the algorithm will make this switch. If the switch increases the\r\n                    number of errors in the board, then the algorithm will not make this\r\n                    switch. It looks at around 50000 moves, but quickly reaches a point\r\n                    where there aren't any moves that will lower the error, even though\r\n                    the grid is not solved. This is called a \"local minimum\" in the error,\r\n                    but it is not the \"absolute minimum\" of 0 error that we want.`\r\n                )\r\n\r\n            case 3: \r\n                return (\r\n                    `Simulated Annealing is based on how molten metals cool into solid\r\n                    form. It is very similar to Hill Climbing. It starts by filling in\r\n                    all the 3x3 squares with the digits 1-9. Then we define the Error\r\n                    as the total number of duplicates in the rows and columns. The 3x3\r\n                    square have no duplicates so the do not contribute to the error.\r\n                    The algorithm then chooses two random 1x1 square in a random 3x3 \r\n                    square. If switching their values decreases the total error in the\r\n                    board, then the algorithm makes this switch. Otherwise, it has a\r\n                    chance to make this switch and a chance to not make this switch.\r\n                    At the beginning, there is about an 80% change that the algorithm\r\n                    will make this \"bad\" switch. Over time, the chance to make a \"bad\"\r\n                    switch goes down so that by the end there is almost a 0% chance.\r\n                    In this way, the algorithm is much like Hill Climbing, but it\r\n                    allows the board to change a lot more at the beginning, and \"cool\"\r\n                    into a solution with less errors. This helps the algorithm break\r\n                    out of local minima in the error that Hill Climbing gets stuck\r\n                    at. If you run both of these a few times, you'll see that Hill\r\n                    Climbing usually ends with around 10 errors, but Simulated\r\n                    Annealing usually ends with 2 or 3, which is much better.`\r\n                )\r\n\r\n            case 4:\r\n                return (\r\n                    `The genetic algorithm replicates natural selection in organisms.\r\n                    It starts off by creating 1000 different random boards. This is\r\n                    the first generation. It counts the number of errors in the\r\n                    rows, columns, and 3x3 squares for each board. It then creates a\r\n                    second generation by making 1000 \"children\" boards from the first\r\n                    generation. A child is created by selecting two \"parent\" boards\r\n                    from the first generation and mixing their values together.\r\n                    Importantly, boards in the first generation with lower errors are\r\n                    selected as parents more often so that children with similarly \r\n                    low errors are produced more than children with higher error. In\r\n                    this way we are \"selecting\" the more fit boards to reproduce more\r\n                    in the same way nature selects more fit organisms to reproduce more.\r\n                    Each child also undergoes a mutation process which gives a small\r\n                    chance for any of its values that it got from its parents to\r\n                    randomly change to another value. This reflects Gene mutation in\r\n                    natural selection. When 1000 children have been created, they\r\n                    become the parents to make the 3rd generation. And those children\r\n                    become parents to make the 4th generation, and so on. This\r\n                    algorithm runs for 1000 generations before stopping.`\r\n                )\r\n            \r\n            default:\r\n                return \"Choose an algorithm!\"\r\n        }\r\n    }\r\n\r\n    render() {\r\n        return (\r\n        <span className='About'>{this.chooseAbout(this.props.selectedAlg)}</span>\r\n        )\r\n    }\r\n}"]},"metadata":{},"sourceType":"module"}